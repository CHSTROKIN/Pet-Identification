{"cells":[{"cell_type":"markdown","metadata":{},"source":["<br>\n","<h2 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">[Pytorch] ArcFace Starter</h2>\n","<br>"]},{"cell_type":"markdown","metadata":{},"source":["<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\"><strong>Update:</strong></span><br>\n","<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">V3: Added Embedding layer between GeM pooling and ArcFace Module. Improves results</span>"]},{"cell_type":"markdown","metadata":{},"source":["<h3>üìå Siamese Starter Notebook:</h3> <h4><a href='https://www.kaggle.com/debarshichanda/pytorch-happywhale-siamese-starter'>https://www.kaggle.com/debarshichanda/pytorch-happywhale-siamese-starter</a></h4>\n","\n","<h3>üìå FAISS Pytorch Inference:</h3> <h4><a href='https://www.kaggle.com/debarshichanda/faiss-pytorch-inference'>https://www.kaggle.com/debarshichanda/faiss-pytorch-inference</a></h4>"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries</h1></span>"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-21T21:41:41.984086Z","iopub.status.busy":"2024-05-21T21:41:41.983516Z","iopub.status.idle":"2024-05-21T21:42:12.583096Z","shell.execute_reply":"2024-05-21T21:42:12.581803Z","shell.execute_reply.started":"2024-05-21T21:41:41.983968Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (1.0.3)\n","Requirement already satisfied: torch in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from timm) (2.3.1)\n","Requirement already satisfied: torchvision in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from timm) (0.18.1)\n","Requirement already satisfied: pyyaml in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from timm) (0.23.3)\n","Requirement already satisfied: safetensors in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: requests in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub->timm) (4.11.0)\n","Requirement already satisfied: sympy in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torch->timm) (3.1)\n","Requirement already satisfied: jinja2 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torch->timm) (3.1.3)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torch->timm) (2021.4.0)\n","Requirement already satisfied: numpy in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torchvision->timm) (1.24.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from torchvision->timm) (10.3.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.12.0)\n","Requirement already satisfied: colorama in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from jinja2->torch->timm) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub->timm) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.6.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: huggingface_hub in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (0.23.3)\n","Requirement already satisfied: filelock in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from huggingface_hub) (4.11.0)\n","Requirement already satisfied: colorama in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests->huggingface_hub) (2024.6.2)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n"]}],"source":["!pip install timm\n","!pip install huggingface_hub"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (0.17.1)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (5.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (5.9.8)\n","Requirement already satisfied: pyyaml in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (2.5.0)\n","Requirement already satisfied: setproctitle in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from wandb) (69.5.1)\n","Requirement already satisfied: colorama in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n","Requirement already satisfied: six>=1.4.0 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\18446\\anaconda3\\envs\\pet\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n","WARNING: Skipping C:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\ipykernel-6.29.3.dist-info due to invalid metadata entry 'name'\n"]}],"source":["!pip install wandb"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries üìö</h1></span>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:42:46.526431Z","iopub.status.busy":"2024-05-21T21:42:46.526064Z","iopub.status.idle":"2024-05-21T21:42:53.219027Z","shell.execute_reply":"2024-05-21T21:42:53.217735Z","shell.execute_reply.started":"2024-05-21T21:42:46.526392Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"]}],"source":["import os\n","import gc\n","import cv2\n","import math\n","import copy\n","import time\n","import random\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","\n","# # For Image Models\n","import timm\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","b_ = Fore.BLUE\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:43:25.194555Z","iopub.status.busy":"2024-05-21T21:43:25.194126Z","iopub.status.idle":"2024-05-21T21:43:26.075682Z","shell.execute_reply":"2024-05-21T21:43:26.074833Z","shell.execute_reply.started":"2024-05-21T21:43:25.194510Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n","Get your W&B access token from here: https://wandb.ai/authorize\n"]}],"source":["import wandb\n","\n","try:\n","    from kaggle_secrets import UserSecretsClient\n","    user_secrets = UserSecretsClient()\n","    wandb.login(key=\"d82672e7b0d92da578d13f9608652d2d7ed38f06\")\n","    anony = None\n","except:\n","    anony = \"must\"\n","    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:11:20.663669Z","iopub.status.busy":"2024-05-21T21:11:20.663290Z","iopub.status.idle":"2024-05-21T21:12:21.423881Z","shell.execute_reply":"2024-05-21T21:12:21.423118Z","shell.execute_reply.started":"2024-05-21T21:11:20.663626Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["wandb: Currently logged in as: chstrokin. Use `wandb login --relogin` to force relogin\n"]}],"source":["!wandb login"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Configuration ‚öôÔ∏è</h1></span>"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:43:37.773740Z","iopub.status.busy":"2024-05-21T21:43:37.773359Z","iopub.status.idle":"2024-05-21T21:43:37.820276Z","shell.execute_reply":"2024-05-21T21:43:37.819541Z","shell.execute_reply.started":"2024-05-21T21:43:37.773700Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                     id                     breed\n","0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n","1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n","2      001cdf01b096e06d78e9e5112d419397                  pekinese\n","3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n","4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n","...                                 ...                       ...\n","10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n","10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n","10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n","10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n","10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n","\n","[10222 rows x 2 columns]\n"]}],"source":["import pandas as pd\n","sample_csv = \"D:\\pet identification\\labels.csv\"\n","csv_file = pd.read_csv(sample_csv)\n","print(csv_file)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:37:23.082313Z","iopub.status.busy":"2024-05-21T21:37:23.081154Z","iopub.status.idle":"2024-05-21T21:37:23.098640Z","shell.execute_reply":"2024-05-21T21:37:23.097071Z","shell.execute_reply.started":"2024-05-21T21:37:23.082258Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["120\n"]}],"source":["print(len(csv_file[\"breed\"].unique()))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:43:52.926228Z","iopub.status.busy":"2024-05-21T21:43:52.925857Z","iopub.status.idle":"2024-05-21T21:43:52.934662Z","shell.execute_reply":"2024-05-21T21:43:52.933846Z","shell.execute_reply.started":"2024-05-21T21:43:52.926188Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'seed': 2022, 'epochs': 4, 'img_size': 448, 'model_name': 'efficientnet_b0', 'num_class': 120, 'embedding_size': 512, 'train_batch_size': 16, 'valid_batch_size': 16, 'learning_rate': 0.0001, 'scheduler': 'CosineAnnealingLR', 'min_lr': 1e-06, 'T_max': 500, 'weight_decay': 1e-06, 'n_fold': 5, 'n_accumulate': 1, 'device': device(type='cuda', index=0), 's': 30.0, 'm': 0.5, 'ls_eps': 0.0, 'easy_margin': False}\n"]}],"source":["CONFIG = {\"seed\": 2022,\n","          \"epochs\": 4,\n","          \"img_size\": 448,\n","          \"model_name\": \"efficientnet_b0\",\n","          \"num_class\": len(csv_file[\"breed\"].unique()),\n","          \"embedding_size\": 512,\n","          \"train_batch_size\":16,\n","          \"valid_batch_size\": 16,\n","          \"learning_rate\": 1e-4,\n","          \"scheduler\": 'CosineAnnealingLR',\n","          \"min_lr\": 1e-6,\n","          \"T_max\": 500,\n","          \"weight_decay\": 1e-6,\n","          \"n_fold\": 5,\n","          \"n_accumulate\": 1,\n","          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","          # ArcFace Hyperparameters\n","          \"s\": 30.0, \n","          \"m\": 0.50,\n","          \"ls_eps\": 0.0,\n","          \"easy_margin\": False\n","          }\n","print(CONFIG)"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility</h1></span>"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:21.675711Z","iopub.status.busy":"2024-05-21T21:44:21.674428Z","iopub.status.idle":"2024-05-21T21:44:21.687907Z","shell.execute_reply":"2024-05-21T21:44:21.686278Z","shell.execute_reply.started":"2024-05-21T21:44:21.675657Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed=42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","set_seed(CONFIG['seed'])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:23.649893Z","iopub.status.busy":"2024-05-21T21:44:23.648873Z","iopub.status.idle":"2024-05-21T21:44:23.655984Z","shell.execute_reply":"2024-05-21T21:44:23.654877Z","shell.execute_reply.started":"2024-05-21T21:44:23.649824Z"},"trusted":true},"outputs":[],"source":["ROOT_DIR = 'D:\\\\pet identification'\n","TRAIN_DIR = 'D:\\\\pet identification\\\\Pet-Identification\\\\archive\\\\images'\n","TEST_DIR = 'D:\\\\pet identification\\\\test'"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:25.507127Z","iopub.status.busy":"2024-05-21T21:44:25.506785Z","iopub.status.idle":"2024-05-21T21:44:25.513407Z","shell.execute_reply":"2024-05-21T21:44:25.512144Z","shell.execute_reply.started":"2024-05-21T21:44:25.507091Z"},"trusted":true},"outputs":[],"source":["def get_train_file_path(id):\n","    return f\"{TRAIN_DIR}\\\\{id}.jpg\""]},{"cell_type":"markdown","metadata":{},"source":["# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Read the Data üìñ</h1>"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:27.132434Z","iopub.status.busy":"2024-05-21T21:44:27.132030Z","iopub.status.idle":"2024-05-21T21:44:27.176208Z","shell.execute_reply":"2024-05-21T21:44:27.175326Z","shell.execute_reply.started":"2024-05-21T21:44:27.132391Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["D:\\pet identification\\Pet-Identification\\archive\\images\\Abyssinian_1.jpg\n","               id        breed  \\\n","0    Abyssinian_1  Abyssinian_   \n","1   Abyssinian_10  Abyssinian_   \n","2  Abyssinian_100  Abyssinian_   \n","3  Abyssinian_101  Abyssinian_   \n","4  Abyssinian_102  Abyssinian_   \n","\n","                                           file_path  \n","0  D:\\pet identification\\Pet-Identification\\archi...  \n","1  D:\\pet identification\\Pet-Identification\\archi...  \n","2  D:\\pet identification\\Pet-Identification\\archi...  \n","3  D:\\pet identification\\Pet-Identification\\archi...  \n","4  D:\\pet identification\\Pet-Identification\\archi...  \n","38\n"]}],"source":["df = pd.read_csv(f\"D:\\\\pet identification\\\\Pet-Identification\\\\output.csv\")\n","df['file_path'] = df['id'].apply(get_train_file_path)\n","df.head()\n","print(df[\"file_path\"][0])\n","print(df.head())\n","print(df[\"breed\"].nunique())\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:28.917016Z","iopub.status.busy":"2024-05-21T21:44:28.916646Z","iopub.status.idle":"2024-05-21T21:44:28.942025Z","shell.execute_reply":"2024-05-21T21:44:28.940128Z","shell.execute_reply.started":"2024-05-21T21:44:28.916978Z"},"trusted":true},"outputs":[],"source":["encoder = LabelEncoder()\n","df['individual_id'] = encoder.fit_transform(df['breed'])\n","\n","with open(\"le.pkl\", \"wb\") as fp:\n","    joblib.dump(encoder, fp)"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Folds</h1></span>"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:26:36.104141Z","iopub.status.busy":"2024-05-21T21:26:36.103396Z","iopub.status.idle":"2024-05-21T21:26:36.147606Z","shell.execute_reply":"2024-05-21T21:26:36.146316Z","shell.execute_reply.started":"2024-05-21T21:26:36.104099Z"},"trusted":true},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n","\n","for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.individual_id)):\n","      df.loc[val_ , \"kfold\"] = fold"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class</h1></span>"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:31.399798Z","iopub.status.busy":"2024-05-21T21:44:31.399320Z","iopub.status.idle":"2024-05-21T21:44:31.410479Z","shell.execute_reply":"2024-05-21T21:44:31.409367Z","shell.execute_reply.started":"2024-05-21T21:44:31.399713Z"},"trusted":true},"outputs":[],"source":["class PetDataset(Dataset):\n","    def __init__(self, df, transforms=None):\n","        self.df = df\n","        self.file_names = df['file_path'].values\n","        self.labels = df['individual_id'].values\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        img_path = self.file_names[index]\n","        img = cv2.imread(img_path)\n","        if(img is None):\n","            print(\"*\"*10)\n","            print(img_path)\n","            print(\"*\"*10)\n","            img =  cv2.imread(img_path)\n","            if(img is None):\n","                return None\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        label = self.labels[index]\n","        \n","        if self.transforms:\n","            img = self.transforms(image=img)[\"image\"]\n","            \n","        return {\n","            'image': img,\n","            'label': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Augmentations</h1></span>"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:34.165244Z","iopub.status.busy":"2024-05-21T21:44:34.164948Z","iopub.status.idle":"2024-05-21T21:44:34.180298Z","shell.execute_reply":"2024-05-21T21:44:34.178717Z","shell.execute_reply.started":"2024-05-21T21:44:34.165210Z"},"trusted":true},"outputs":[],"source":["data_transforms = {\n","    \"train\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.ShiftScaleRotate(shift_limit=0.1, \n","                           scale_limit=0.15, \n","                           rotate_limit=60, \n","                           p=0.5),\n","        A.HueSaturationValue(\n","                hue_shift_limit=0.2, \n","                sat_shift_limit=0.2, \n","                val_shift_limit=0.2, \n","                p=0.5\n","            ),\n","        A.RandomBrightnessContrast(\n","                brightness_limit=(-0.1,0.1), \n","                contrast_limit=(-0.1, 0.1), \n","                p=0.5\n","            ),\n","        A.Normalize(\n","                mean=[0.485, 0.456, 0.406], \n","                std=[0.229, 0.224, 0.225], \n","                max_pixel_value=255.0, \n","                p=1.0\n","            ),\n","        ToTensorV2()], p=1.),\n","    \n","    \"valid\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(\n","                mean=[0.485, 0.456, 0.406], \n","                std=[0.229, 0.224, 0.225], \n","                max_pixel_value=255.0, \n","                p=1.0\n","            ),\n","        ToTensorV2()], p=1.)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">GeM Pooling</h1></span>\n","\n","<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://amaarora.github.io/2020/08/30/gempool.html\">GeM Pooling Explained</a></span>\n","\n","![](https://i.imgur.com/thTgYWG.jpg)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:38.356728Z","iopub.status.busy":"2024-05-21T21:44:38.356374Z","iopub.status.idle":"2024-05-21T21:44:38.368607Z","shell.execute_reply":"2024-05-21T21:44:38.367669Z","shell.execute_reply.started":"2024-05-21T21:44:38.356690Z"},"trusted":true},"outputs":[],"source":["class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        self.p = nn.Parameter(torch.ones(1)*p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return self.gem(x, p=self.p, eps=self.eps)\n","        \n","    def gem(self, x, p=3, eps=1e-6):\n","        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n","        \n","    def __repr__(self):\n","        return self.__class__.__name__ + \\\n","                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n","                ', ' + 'eps=' + str(self.eps) + ')'"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">ArcFace</h1></span>\n","\n","<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Code taken from <a href=\"https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\">Landmark2019-1st-and-3rd-Place-Solution</a></span>"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:40.326156Z","iopub.status.busy":"2024-05-21T21:44:40.325838Z","iopub.status.idle":"2024-05-21T21:44:40.344433Z","shell.execute_reply":"2024-05-21T21:44:40.343134Z","shell.execute_reply.started":"2024-05-21T21:44:40.326122Z"},"trusted":true},"outputs":[],"source":["class ArcMarginProduct(nn.Module):\n","    r\"\"\"Implement of large margin arc distance: :\n","        Args:\n","            in_features: size of each input sample\n","            out_features: size of each output sample\n","            s: norm of input feature\n","            m: margin\n","            cos(theta + m)\n","        \"\"\"\n","    def __init__(self, in_features, out_features, s=30.0, \n","                 m=0.50, easy_margin=False, ls_eps=0.0):\n","        super(ArcMarginProduct, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.s = s\n","        self.m = m\n","        self.ls_eps = ls_eps  # label smoothing\n","        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n","        nn.init.xavier_uniform_(self.weight)\n","\n","        self.easy_margin = easy_margin\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.th = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","\n","    def forward(self, input, label):\n","        # --------------------------- cos(theta) & phi(theta) ---------------------\n","        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n","        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        if self.easy_margin:\n","            phi = torch.where(cosine > 0, phi, cosine)\n","        else:\n","            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n","        # --------------------------- convert label to one-hot ---------------------\n","        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n","        one_hot = torch.zeros(cosine.size(), device=CONFIG['device'])\n","        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n","        if self.ls_eps > 0:\n","            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n","        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n","        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n","        output *= self.s\n","\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model</h1></span>"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-21T21:44:44.032660Z","iopub.status.busy":"2024-05-21T21:44:44.032135Z","iopub.status.idle":"2024-05-21T21:44:44.335311Z","shell.execute_reply":"2024-05-21T21:44:44.333823Z","shell.execute_reply.started":"2024-05-21T21:44:44.032619Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b0.ra_in1k)\n","INFO:timm.models._hub:[timm/efficientnet_b0.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"]}],"source":["class DogImageModel(nn.Module):\n","    def __init__(self, model_name, embedding_size, pretrained=True):\n","        super(DogImageModel, self).__init__()\n","        self.model = timm.create_model(model_name, pretrained=pretrained)\n","        in_features = self.model.classifier.in_features\n","        self.model.classifier = nn.Identity()\n","        self.model.global_pool = nn.Identity()\n","        self.pooling = GeM()\n","        self.embedding = nn.Linear(in_features, embedding_size)\n","        self.fc = ArcMarginProduct(embedding_size, \n","                                   CONFIG[\"num_class\"],\n","                                   s=CONFIG[\"s\"], \n","                                   m=CONFIG[\"m\"], \n","                                   easy_margin=CONFIG[\"ls_eps\"], \n","                                   ls_eps=CONFIG[\"ls_eps\"])\n","\n","    def forward(self, images, labels):\n","        features = self.model(images)\n","        pooled_features = self.pooling(features).flatten(1)\n","        embedding = self.embedding(pooled_features)\n","        output = self.fc(embedding, labels)\n","        return output\n","    \n","    def extract(self, images):\n","        features = self.model(images)\n","        pooled_features = self.pooling(features).flatten(1)\n","        embedding = self.embedding(pooled_features)\n","        return embedding\n","\n","    \n","model = DogImageModel(CONFIG['model_name'], CONFIG['embedding_size'])\n","model.load_state_dict(torch.load(\"D:\\\\pet identification\\\\Pet-Identification\\\\Loss1.9962_epoch7.bin\"))\n","model.to(CONFIG['device']);"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function</h1></span>"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.075520Z","iopub.status.idle":"2022-03-16T12:57:25.076331Z","shell.execute_reply":"2022-03-16T12:57:25.076120Z","shell.execute_reply.started":"2022-03-16T12:57:25.076096Z"},"trusted":true},"outputs":[],"source":["def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function</h1></span>"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.077452Z","iopub.status.idle":"2022-03-16T12:57:25.078116Z","shell.execute_reply":"2022-03-16T12:57:25.077882Z","shell.execute_reply.started":"2022-03-16T12:57:25.077858Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    print('begin one epoch')\n","    print(f'')\n","    model.train()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    # print('start training')\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    # print('bar created')\n","    for step, data in bar:\n","        # print('step is', step)\n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        # print('images and labels are loaded')\n","        batch_size = images.size(0)\n","        # print(f'step is {step} and batch size is {batch_size}')\n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        loss = loss / CONFIG['n_accumulate']\n","        # print('loss calculated')\n","        loss.backward()\n","        # print('loss backward')\n","        if (step + 1) % CONFIG['n_accumulate'] == 0:\n","            optimizer.step()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            if scheduler is not None:\n","                scheduler.step()\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])\n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Validation Function</h1></span>"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.079660Z","iopub.status.idle":"2022-03-16T12:57:25.080501Z","shell.execute_reply":"2022-03-16T12:57:25.080210Z","shell.execute_reply.started":"2022-03-16T12:57:25.080181Z"},"trusted":true},"outputs":[],"source":["@torch.inference_mode()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","    \n","    dataset_size = 0\n","    running_loss = 0.0\n","    \n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for step, data in bar:        \n","        images = data['image'].to(device, dtype=torch.float)\n","        labels = data['label'].to(device, dtype=torch.long)\n","        \n","        batch_size = images.size(0)\n","\n","        outputs = model(images, labels)\n","        loss = criterion(outputs, labels)\n","        \n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","        \n","        epoch_loss = running_loss / dataset_size\n","        \n","        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n","                        LR=optimizer.param_groups[0]['lr'])   \n","    \n","    gc.collect()\n","    \n","    return epoch_loss"]},{"cell_type":"markdown","metadata":{},"source":["# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training</h1></span>"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.082501Z","iopub.status.idle":"2022-03-16T12:57:25.082913Z","shell.execute_reply":"2022-03-16T12:57:25.082718Z","shell.execute_reply.started":"2022-03-16T12:57:25.082696Z"},"trusted":true},"outputs":[],"source":["def run_training(model, optimizer, scheduler, device, num_epochs, train_loader, valid_loader):\n","    # To automatically log gradients\n","    wandb.watch(model, log_freq=100)\n","    \n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n","    \n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_epoch_loss = np.inf\n","    history = defaultdict(list)\n","    # print('Training Started')\n","    for epoch in range(1, num_epochs + 1): \n","        # print('Garbage collection in progress')\n","        gc.collect()\n","        # print('end=====================')\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n","                                           dataloader=train_loader, \n","                                           device=CONFIG['device'], epoch=epoch)\n","        \n","        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n","                                         epoch=epoch)\n","    \n","        history['Train Loss'].append(train_epoch_loss)\n","        history['Valid Loss'].append(val_epoch_loss)\n","        # print(f'Total loss is {train_epoch_loss}')\n","        # Log the metrics\n","        wandb.log({\"Train Loss\": train_epoch_loss})\n","        wandb.log({\"Valid Loss\": val_epoch_loss})\n","        \n","        # deep copy the model\n","        if val_epoch_loss <= best_epoch_loss:\n","            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n","            best_epoch_loss = val_epoch_loss\n","            run.summary[\"Best Loss\"] = best_epoch_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n","            torch.save(model.state_dict(), PATH)\n","            # Save a model file from the current directory\n","            print(f\"Model Saved{sr_}\")\n","            \n","        print()\n","    \n","    end = time.time()\n","    time_elapsed = end - start\n","    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n","    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n","    \n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    \n","    return model, history"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.084267Z","iopub.status.idle":"2022-03-16T12:57:25.084682Z","shell.execute_reply":"2022-03-16T12:57:25.084477Z","shell.execute_reply.started":"2022-03-16T12:57:25.084455Z"},"trusted":true},"outputs":[],"source":["def fetch_scheduler(optimizer):\n","    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n","        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n","                                                   eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n","        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n","                                                             eta_min=CONFIG['min_lr'])\n","    elif CONFIG['scheduler'] == None:\n","        return None\n","        \n","    return scheduler"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.086121Z","iopub.status.idle":"2022-03-16T12:57:25.086526Z","shell.execute_reply":"2022-03-16T12:57:25.086330Z","shell.execute_reply.started":"2022-03-16T12:57:25.086309Z"},"trusted":true},"outputs":[],"source":["\n","def prepare_loaders(df, fold):\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    train_dataset = PetDataset(df_train, transforms=data_transforms[\"train\"])\n","    valid_dataset = PetDataset(df_valid, transforms=data_transforms[\"valid\"])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n","                              num_workers=0, shuffle=True, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n","                              num_workers=0, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader\n","train_loader, valid_loader = prepare_loaders(df, fold=2)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["train_loader, valid_loader = prepare_loaders(df, fold=0)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.089674Z","iopub.status.idle":"2022-03-16T12:57:25.090093Z","shell.execute_reply":"2022-03-16T12:57:25.089878Z","shell.execute_reply.started":"2022-03-16T12:57:25.089856Z"},"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n","                       weight_decay=CONFIG['weight_decay'])\n","scheduler = fetch_scheduler(optimizer)"]},{"cell_type":"markdown","metadata":{},"source":["<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training</span>"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.091356Z","iopub.status.idle":"2022-03-16T12:57:25.091765Z","shell.execute_reply":"2022-03-16T12:57:25.091561Z","shell.execute_reply.started":"2022-03-16T12:57:25.091539Z"},"trusted":true},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.17.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>d:\\pet identification\\Pet-Identification\\wandb\\run-20240616_201223-9kq4oge9</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/chstrokin/Pet-Identification/runs/9kq4oge9' target=\"_blank\">crisp-forest-14</a></strong> to <a href='https://wandb.ai/chstrokin/Pet-Identification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/chstrokin/Pet-Identification' target=\"_blank\">https://wandb.ai/chstrokin/Pet-Identification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/chstrokin/Pet-Identification/runs/9kq4oge9' target=\"_blank\">https://wandb.ai/chstrokin/Pet-Identification/runs/9kq4oge9</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["run = wandb.init(project='Pet-Identification', \n","                 config=CONFIG,\n","                 job_type='Train',\n","                 tags=['arcface', 'gem-pooling', 'effnet-b0-ns', '448'],\n","                 anonymous='must')"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.092942Z","iopub.status.idle":"2022-03-16T12:57:25.093558Z","shell.execute_reply":"2022-03-16T12:57:25.093321Z","shell.execute_reply.started":"2022-03-16T12:57:25.093294Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO] Using GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n","\n","begin one epoch\n","\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 1/363 [00:00<03:20,  1.81it/s, Epoch=1, LR=9.23e-5, Train_Loss=0.571]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[34], line 17\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, optimizer, scheduler, device, num_epochs, train_loader, valid_loader)\u001b[0m\n\u001b[0;32m     15\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# print('end=====================')\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m train_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m val_epoch_loss \u001b[38;5;241m=\u001b[39m valid_one_epoch(model, valid_loader, device\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     22\u001b[0m                                  epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m     24\u001b[0m history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n","Cell \u001b[1;32mIn[32], line 18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(f'step is {step} and batch size is {batch_size}')\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_accumulate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[30], line 18\u001b[0m, in \u001b[0;36mDogImageModel.forward\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, labels):\n\u001b[1;32m---> 18\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     pooled_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling(features)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(pooled_features)\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\timm\\models\\efficientnet.py:259\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 259\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\timm\\models\\efficientnet.py:247\u001b[0m, in \u001b[0;36mEfficientNet.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    245\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, x, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_head(x)\n\u001b[0;32m    249\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\timm\\models\\_efficientnet_blocks.py:186\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mse(x)\n\u001b[0;32m    185\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_pwl(x)\n\u001b[1;32m--> 186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_skip:\n\u001b[0;32m    188\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(x) \u001b[38;5;241m+\u001b[39m shortcut\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\timm\\layers\\norm_act.py:118\u001b[0m, in \u001b[0;36mBatchNormAct2d.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    111\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(x)\n\u001b[0;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n","File \u001b[1;32mc:\\Users\\18446\\anaconda3\\envs\\pet\\Lib\\site-packages\\torch\\nn\\functional.py:2509\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2507\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model, history = run_training(model, optimizer, scheduler,\n","                              device=CONFIG['device'],\n","                              num_epochs=50, train_loader=train_loader, valid_loader=valid_loader)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:57:25.094830Z","iopub.status.idle":"2022-03-16T12:57:25.095790Z","shell.execute_reply":"2022-03-16T12:57:25.095568Z","shell.execute_reply.started":"2022-03-16T12:57:25.095543Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32247072ee854cdc90ca9106469dec6d","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>Valid Loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Loss</td><td>6.00865</td></tr><tr><td>Train Loss</td><td>0.31098</td></tr><tr><td>Valid Loss</td><td>7.01459</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">lilac-durian-9</strong> at: <a href='https://wandb.ai/chstrokin/Pet-Identification/runs/rwlezl0d' target=\"_blank\">https://wandb.ai/chstrokin/Pet-Identification/runs/rwlezl0d</a><br/> View project at: <a href='https://wandb.ai/chstrokin/Pet-Identification' target=\"_blank\">https://wandb.ai/chstrokin/Pet-Identification</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>.\\wandb\\run-20240608_032329-rwlezl0d\\logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["run.finish()"]},{"cell_type":"markdown","metadata":{},"source":["# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualizations</h1>\n","\n","<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/dchanda/HappyWhale/runs/3l3k91tm\">View the Complete Dashboard Here ‚Æï</a></span>"]},{"cell_type":"markdown","metadata":{},"source":["![](https://i.imgur.com/3Cc8KBH.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861871,"sourceId":7327,"sourceType":"competition"}],"dockerImageVersionId":30158,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
